{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f33252d",
   "metadata": {},
   "source": [
    "# Documentation du Dataset pour l'Environnement RL\n",
    "\n",
    "Ce document décrit en détail la préparation du jeu de données issu des fichiers ATUS pour entraîner un agent Deep Q-Network (DQN) dans un environnement de gestion du temps.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Contexte et objectifs\n",
    "\n",
    "L'objectif est de simuler un calendrier d'activités à partir de données réelles (American Time Use Survey) pour :\n",
    "\n",
    "* Construire un **environnement Gym-like** exposant un état (créneaux, type d'activité, lieu, contexte) et acceptant des actions (allocation de tâches).\n",
    "* Entraîner un **agent DQN** capable de proposer des plannings optimaux.\n",
    "* Itérer via un **feedback utilisateur** pour améliorer la productivité.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Sources de données\n",
    "\n",
    "Les fichiers bruts (`data/raw/`) :\n",
    "\n",
    "1. **atusact.csv** : journal minute-par-minute des activités\n",
    "2. **codes.csv** : correspondance `code` → `name` des activités\n",
    "3. **atusresp.csv** : données démographiques et contexte du répondant\n",
    "4. **atuswgts.csv** : poids d'échantillonnage pour chaque journal\n",
    "5. **atussum.csv** : résumé agrégé journalier par catégorie\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Colonnes retenues\n",
    "\n",
    "Pour un proof-of-concept, seules les colonnes suivantes sont nécessaires :\n",
    "\n",
    "| Colonne         | Origine               | Description                                                      |\n",
    "| --------------- | --------------------- | ---------------------------------------------------------------- |\n",
    "| `TUCASEID`      | atusact,resp,wgts,sum | Identifiant unique du journal (utilisateur+jour)                 |\n",
    "| `TUACTIVITY_N`  | atusact               | Code numérique de l'activité                                     |\n",
    "| `ACTIVITY_NAME` | codes                 | Libellé textuel de l'activité                                    |\n",
    "| `TUACTDUR24`    | atusact               | Durée de l'activité en minutes                                   |\n",
    "| `TUSTARTTIM`    | atusact               | Heure de début (format HHMM)                                     |\n",
    "| `TEWHERE`       | atusact               | Code du lieu d'exécution de l'activité                           |\n",
    "| `TUDIARYDAY`    | atusresp              | Jour de la semaine (1=Lundi … 7=Dimanche)                        |\n",
    "| `TUFNWGTP001`   | atuswgts              | Poids d'échantillonnage principal                                |\n",
    "| `TUFNWGTP002`   | atuswgts              | Poids secondaire (optionnel)                                     |\n",
    "| `GEMETSTA`      | atussum               | Code d'état général du jour (semaine vs. week-end, etc.)         |\n",
    "| `GTMETSTA`      | atussum               | Code de synthèse temporelle (type de jour métier vs. non-métier) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78626f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    'TUCASEID': 'user_id',\n",
    "    'TUACTIVITY_N': 'activity_code',\n",
    "    'ACTIVITY_NAME': 'activity_name',\n",
    "    'TUACTDUR24': 'duration_minutes',\n",
    "    'TUSTARTTIM': 'start_time',\n",
    "    'TEWHERE': 'location_code',\n",
    "    'TUDIARYDAY': 'day_of_week',\n",
    "    'TEAGE': 'age',\n",
    "    'TESEX': 'sex',\n",
    "    'TUFNWGTP001': 'weight_main',\n",
    "    'TUFNWGTP002': 'weight_secondary',\n",
    "    'GEMETSTA': 'general_state',\n",
    "    'GTMETSTA': 'temporal_state'\n",
    "}\n",
    "# Exemple d'application :\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/raw/donnees_nettoyees.csv')\n",
    "df.rename(columns=col_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_data_exploration.ipynb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement et renommage\n",
    "col_map = { ... }  # cf. section commune\n",
    "df = pd.read_csv('data/raw/donnees_nettoyees.csv')\n",
    "df.rename(columns=col_map, inplace=True)\n",
    "\n",
    "# Aperçu général\n",
    "display(df.head())\n",
    "\n",
    "df['activity_name'].value_counts().plot(kind='bar', title='Répartition des activités')\n",
    "plt.xlabel('Activité')\n",
    "plt.ylabel('Nombre d'observations')\n",
    "plt.show()\n",
    "\n",
    "# Statistiques simples\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b52f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles : ['TUCASEID', 'TUACTIVITY_N', 'TUACTDUR24', 'TUSTARTTIM', 'TEWHERE', 'ACTIVITY_NAME', 'TUDIARYDAY', 'TUFNWGTP001', 'TUFNWGTP002', 'GEMETSTA', 'GTMETSTA', 'ACTIVITY_NAME_CLEANED', 'ACTIVITY_NAME_Caring For & Helping Household (HH) Members', 'ACTIVITY_NAME_Caring for & Helping Nonhousehold (NonHH) Members', 'ACTIVITY_NAME_Consumer Purchases', 'ACTIVITY_NAME_Data Codes', 'ACTIVITY_NAME_Eating and Drinking', 'ACTIVITY_NAME_Education', 'ACTIVITY_NAME_Government Services & Civic Obligations', 'ACTIVITY_NAME_Household Activities', 'ACTIVITY_NAME_Household Services', 'ACTIVITY_NAME_Personal Care Activities', 'ACTIVITY_NAME_Professional & Personal Care Services', 'ACTIVITY_NAME_Religious and Spiritual Activities', 'ACTIVITY_NAME_Socializing, Relaxing, and Leisure', 'ACTIVITY_NAME_Sports, Exercise, & Recreation', 'ACTIVITY_NAME_Telephone Calls', 'ACTIVITY_NAME_Traveling', 'ACTIVITY_NAME_Volunteer Activities', 'ACTIVITY_NAME_Work & Work-Related Activities', 'TUACTDUR24_scaled', 'start_time', 'end_time', 'hour', 'time_of_day', 'duration_category']\n",
      "           TUCASEID  TUACTIVITY_N    TUACTDUR24       TEWHERE\n",
      "count  2.583983e+06  2.583983e+06  2.583983e+06  2.583983e+06\n",
      "mean   2.008587e+13  8.377223e+00  7.451903e+01  4.298248e+00\n",
      "std    3.815244e+10  4.835362e+00  9.948129e+01  6.908831e+00\n",
      "min    2.003010e+13  1.000000e+00  1.000000e+00 -3.000000e+00\n",
      "25%    2.005071e+13  4.000000e+00  1.500000e+01  1.000000e+00\n",
      "50%    2.008121e+13  8.000000e+00  3.000000e+01  1.000000e+00\n",
      "75%    2.012030e+13  1.200000e+01  9.000000e+01  9.000000e+00\n",
      "max    2.015121e+13  5.000000e+01  1.313000e+03  9.900000e+01\n",
      "Valeurs uniques pour DAY: [6 7 5 2 3 1 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ACTIVITY_NAME\n",
       "Personal Care Activities                             170842\n",
       "Household Activities                                 170842\n",
       "Caring For & Helping Household (HH) Members          170842\n",
       "Caring for & Helping Nonhousehold (NonHH) Members    170842\n",
       "Work & Work-Related Activities                       170842\n",
       "Education                                            169904\n",
       "Consumer Purchases                                   168503\n",
       "Professional & Personal Care Services                166347\n",
       "Household Services                                   163210\n",
       "Government Services & Civic Obligations              159192\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1_data_exploration.ipynb\n",
    "# Objectif : explorer le dataset nettoyé pour identifier les colonnes utiles\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement du dataset nettoyé\n",
    "df = pd.read_csv('../data/raw/donnees_nettoyees.csv')\n",
    "\n",
    "# Colonnes du dataset\n",
    "print(\"Colonnes disponibles :\", df.columns.tolist())\n",
    "\n",
    "# Statistiques basiques\n",
    "print(df[['TUCASEID','TUACTIVITY_N','TUACTDUR24','TUSTARTTIM','TEWHERE']].describe())\n",
    "print(\"Valeurs uniques pour DAY:\", df['TUDIARYDAY'].unique())\n",
    "\n",
    "# Vérifier la distribution des activités\n",
    "activity_counts = df['ACTIVITY_NAME'].value_counts()\n",
    "activity_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae905e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚠️  Colonnes RESP manquantes, ignorées: {'TESEX', 'TEAGE'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset final prêt : data/raw\\atus_full_selected.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 0. Paramètres de chemin ---\n",
    "DATA_RAW       = '../data/raw/sample_small'\n",
    "DATA_PROCESSED = '../data/raw'\n",
    "os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "\n",
    "ACT_PATH    = os.path.join(DATA_RAW, 'atusact.csv')\n",
    "CODES_PATH  = os.path.join(DATA_RAW, 'codes.csv')\n",
    "RESP_PATH   = os.path.join(DATA_RAW, 'atusresp.csv')\n",
    "WGTS_PATH   = os.path.join(DATA_RAW, 'atuswgts.csv')\n",
    "SUM_PATH    = os.path.join(DATA_RAW, 'atussum.csv')\n",
    "OUTPUT_PATH = os.path.join(DATA_PROCESSED, 'atus_full_selected.csv')\n",
    "\n",
    "# --- 1. Chargement des petits jeux (en mémoire) ---\n",
    "try:\n",
    "    codes = pd.read_csv(CODES_PATH, dtype=str)\n",
    "    resp  = pd.read_csv(RESP_PATH, dtype=str)\n",
    "    wgts  = pd.read_csv(WGTS_PATH, dtype=str)\n",
    "    summ  = pd.read_csv(SUM_PATH, dtype=str)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erreur : impossible de charger un fichier : {e}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- 2. Mise en majuscules des noms de colonnes pour homogénéité ---\n",
    "for df in (codes, resp, wgts, summ):\n",
    "    df.columns = df.columns.str.upper()\n",
    "\n",
    "# --- 3. Renommage dans `codes` pour harmoniser ---\n",
    "codes = codes.rename(columns={\n",
    "    'CODE': 'TUACTIVITY_N',\n",
    "    'NAME': 'ACTIVITY_NAME'\n",
    "})\n",
    "\n",
    "# --- 4. Définition des colonnes souhaitées ---\n",
    "desired_resp = ['TUCASEID', 'TEAGE', 'TESEX', 'TUDIARYDAY']\n",
    "desired_wgts = ['TUCASEID', 'TUFNWGTP001', 'TUFNWGTP002']\n",
    "desired_summ = ['TUCASEID', 'GEMETSTA', 'GTMETSTA']\n",
    "\n",
    "# 5. Intersection : ne garder que ce qui existe réellement\n",
    "avail_resp = [c for c in desired_resp if c in resp.columns]\n",
    "avail_wgts = [c for c in desired_wgts if c in wgts.columns]\n",
    "avail_summ = [c for c in desired_summ if c in summ.columns]\n",
    "\n",
    "if len(avail_resp) < len(desired_resp):\n",
    "    missing = set(desired_resp) - set(avail_resp)\n",
    "    print(f\"⚠️  Colonnes RESP manquantes, ignorées: {missing}\", file=sys.stderr)\n",
    "if len(avail_wgts) < len(desired_wgts):\n",
    "    missing = set(desired_wgts) - set(avail_wgts)\n",
    "    print(f\"⚠️  Colonnes WGTS manquantes, ignorées: {missing}\", file=sys.stderr)\n",
    "if len(avail_summ) < len(desired_summ):\n",
    "    missing = set(desired_summ) - set(avail_summ)\n",
    "    print(f\"⚠️  Colonnes SUM manquantes, ignorées: {missing}\", file=sys.stderr)\n",
    "\n",
    "# On sélectionne uniquement ces colonnes dans les dataframes\n",
    "resp = resp[avail_resp]\n",
    "wgts = wgts[avail_wgts]\n",
    "summ = summ[avail_summ]\n",
    "\n",
    "# --- 6. Traitement du fichier atusact par chunks ---\n",
    "# Colonnes d'intérêt dans atusact\n",
    "act_cols = [\n",
    "    'TUCASEID', 'TULINENO',\n",
    "    'TUACTIVITY_N', 'TUACTDUR24',\n",
    "    'TUSTARTTIM', 'TEWHERE'\n",
    "]\n",
    "\n",
    "chunksize   = 500_000\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(ACT_PATH, dtype=str, chunksize=chunksize):\n",
    "    # a) uniformiser en majuscules\n",
    "    chunk.columns = chunk.columns.str.upper()\n",
    "    # b) ne garder que les colonnes utiles si elles existent\n",
    "    keep = [c for c in act_cols if c in chunk.columns]\n",
    "    chunk = chunk[keep]\n",
    "    # c) fusion code → description (si TUACTIVITY_N présent)\n",
    "    if 'TUACTIVITY_N' in chunk.columns:\n",
    "        chunk = chunk.merge(codes[['TUACTIVITY_N', 'ACTIVITY_NAME']],\n",
    "                            on='TUACTIVITY_N', how='left')\n",
    "    # d) fusion RESP, WGTS, SUM\n",
    "    if 'TUCASEID' in chunk.columns:\n",
    "        chunk = chunk.merge(resp, on='TUCASEID', how='left')\n",
    "        chunk = chunk.merge(wgts, on='TUCASEID', how='left')\n",
    "        chunk = chunk.merge(summ, on='TUCASEID', how='left')\n",
    "    # e) écriture incrémentale dans le fichier de sortie\n",
    "    chunk.to_csv(\n",
    "        OUTPUT_PATH,\n",
    "        mode='w' if first_chunk else 'a',\n",
    "        index=False,\n",
    "        header=first_chunk\n",
    "    )\n",
    "    first_chunk = False\n",
    "\n",
    "print(f\"✅ Dataset final prêt : {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcaa04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
