# Assistant Personnel pour la Gestion du Temps

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.12.0-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.24.0-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Une application intelligente conÃ§ue pour optimiser votre emploi du temps quotidien ou hebdomadaire en utilisant un algorithme d'apprentissage par renforcement basÃ© sur Deep Q-Network (DQN). Ce projet analyse vos habitudes et prÃ©fÃ©rences pour suggÃ©rer des plannings qui maximisent votre productivitÃ© et votre satisfaction.

## ğŸ“‹ Table des matiÃ¨res

- [AperÃ§u du projet](#aperÃ§u-du-projet)
- [CaractÃ©ristiques principales](#caractÃ©ristiques-principales)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Structure du projet](#structure-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [MÃ©thodologie](#mÃ©thodologie)
- [RÃ©sultats attendus](#rÃ©sultats-attendus)
- [Limitations](#limitations)
- [AmÃ©liorations futures](#amÃ©liorations-futures)
- [Contribution](#contribution)
- [Licence](#licence)

## ğŸ¯ AperÃ§u du projet

L'objectif de ce projet est de crÃ©er un assistant personnel qui aide les utilisateurs Ã  planifier leurs journÃ©es ou semaines de maniÃ¨re optimale. En exploitant les donnÃ©es historiques des activitÃ©s et un environnement de simulation basÃ© sur OpenAI Gym, le modÃ¨le DQN propose des emplois du temps adaptÃ©s aux prÃ©fÃ©rences de l'utilisateur tout en respectant des contraintes horaires spÃ©cifiques.

## âœ¨ CaractÃ©ristiques principales

- **Optimisation intelligente** : Utilisation d'un algorithme DQN pour gÃ©nÃ©rer des plannings optimisÃ©s
- **Personnalisation** : PossibilitÃ© de dÃ©finir des activitÃ©s personnalisÃ©es et des contraintes horaires
- **Visualisation interactive** : Interface utilisateur Streamlit avec des graphiques Plotly pour visualiser les plannings quotidiens et hebdomadaires
- **Analyse des performances** : Statistiques sur la productivitÃ© et la rÃ©partition des activitÃ©s
- **Exportation** : TÃ©lÃ©chargement des plannings sous forme de fichiers CSV

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python** : Langage principal pour le dÃ©veloppement
- **TensorFlow** : Pour l'implÃ©mentation et l'entraÃ®nement du modÃ¨le DQN
- **OpenAI Gym** : Pour la crÃ©ation d'un environnement de simulation personnalisÃ©
- **Streamlit** : Pour l'interface utilisateur interactive
- **Pandas/NumPy** : Pour le prÃ©traitement et la manipulation des donnÃ©es
- **Plotly/Matplotlib/Seaborn** : Pour les visualisations de donnÃ©es
- **Scikit-learn** : Pour l'encodage des donnÃ©es catÃ©goriques

## ğŸ“ Structure du projet

```
ğŸ“ Optimisation-de-plannings-avec-DQN/
â”œâ”€â”€ ğŸ“ Data/                  # DonnÃ©es du projet
â”‚   â”œâ”€â”€ ğŸ“ Processed/        # DonnÃ©es prÃ©traitÃ©es
â”‚   â”‚   â”œâ”€â”€ activity_encoder.pkl
â”‚   â”‚   â””â”€â”€ cleaned_data.csv
â”‚   â””â”€â”€ ğŸ“ raw/              # DonnÃ©es brutes
â”‚       â””â”€â”€ atus_full_selected.csv
â”œâ”€â”€ ğŸ“ environment/          # Environnement RL personnalisÃ©
â”‚   â”œâ”€â”€ ğŸ“„ schedule_env.py  # ImplÃ©mentation de l'environnement Gym
â”œâ”€â”€ ğŸ“ models/              # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ dqn_final.h5
â”‚   â””â”€â”€ dqn_schedule_model.h5
â”œâ”€â”€ ğŸ“ notebooks/           # Notebooks Jupyter
â”‚   â”œâ”€â”€ 2_data_preprocessing.ipynb  # PrÃ©traitement des donnÃ©es
â”‚   â””â”€â”€ 3_dqn_training.ipynb       # EntraÃ®nement du DQN
â””â”€â”€ ğŸ“ ui/                  # Interface utilisateur
    â””â”€â”€ ğŸ“„ app.py          # Application Streamlit
```

### Description des fichiers

#### ğŸ“‚ Data/
Contient les donnÃ©es brutes (`raw/`) et prÃ©traitÃ©es (`Processed/`).
- `atus_full_selected.csv` : DonnÃ©es brutes des activitÃ©s (extraites de l'American Time Use Survey ou synthÃ©tiques pour les tests)
- `cleaned_data.csv` : DonnÃ©es nettoyÃ©es et prÃªtes pour l'entraÃ®nement
- `activity_encoder.pkl` : Encodeur pour les noms d'activitÃ©s

#### ğŸ“‚ environment/
- `schedule_env.py` : ImplÃ©mentation de l'environnement Gym pour simuler la planification des activitÃ©s

#### ğŸ“‚ models/
ModÃ¨les DQN entraÃ®nÃ©s.
- `dqn_schedule_model.h5` : ModÃ¨le principal utilisÃ© par l'application
- `dqn_final.h5` : ModÃ¨le final sauvegardÃ© aprÃ¨s l'entraÃ®nement

#### ğŸ“‚ notebooks/
- `2_data_preprocessing.ipynb` : PrÃ©traitement des donnÃ©es, incluant le nettoyage, la conversion des heures, et l'encodage des activitÃ©s
- `3_dqn_training.ipynb` : EntraÃ®nement du modÃ¨le DQN avec suivi des rÃ©compenses et des pertes

#### ğŸ“‚ ui/
- `app.py` : Application Streamlit pour interagir avec l'utilisateur, gÃ©nÃ©rer des plannings, et visualiser les rÃ©sultats

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- pip (gestionnaire de paquets Python)
- Environnement virtuel (recommandÃ©)

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t :**
   ```bash
   git clone https://github.com/votre-nom/Optimisation-de-plannings-avec-DQN.git
   cd Optimisation-de-plannings-avec-DQN
   ```

2. **CrÃ©er et activer un environnement virtuel :**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows : venv\Scripts\activate
   ```

3. **Installer les dÃ©pendances :**
   ```bash
   pip install -r requirements.txt
   ```

4. **CrÃ©er un fichier `requirements.txt` avec les dÃ©pendances suivantes :**
   ```txt
   tensorflow==2.12.0
   gym==0.23.1
   streamlit==1.24.0
   pandas==1.5.3
   numpy==1.24.3
   matplotlib==3.7.1
   seaborn==0.12.2
   plotly==5.14.1
   scikit-learn==1.2.2
   tqdm==4.65.0
   ```

5. **VÃ©rifier les donnÃ©es :**
   Placez vos donnÃ©es brutes dans `Data/raw/atus_full_selected.csv` ou utilisez les donnÃ©es synthÃ©tiques gÃ©nÃ©rÃ©es automatiquement par l'environnement.

## ğŸ’» Utilisation

### 1. PrÃ©traitement des donnÃ©es

ExÃ©cutez le notebook `2_data_preprocessing.ipynb` pour nettoyer et transformer les donnÃ©es brutes :

```bash
jupyter notebook notebooks/2_data_preprocessing.ipynb
```

Ce notebook gÃ©nÃ¨re `cleaned_data.csv` et `activity_encoder.pkl` dans `Data/Processed/`.

### 2. EntraÃ®nement du modÃ¨le DQN

ExÃ©cutez le notebook `3_dqn_training.ipynb` pour entraÃ®ner le modÃ¨le DQN :

```bash
jupyter notebook notebooks/3_dqn_training.ipynb
```

Le modÃ¨le entraÃ®nÃ© est sauvegardÃ© dans `models/dqn_schedule_model.h5`.

### 3. Lancer l'application Streamlit

Lancez l'application utilisateur avec la commande suivante :

```bash
streamlit run ui/app.py
```

L'application s'ouvre dans votre navigateur par dÃ©faut. Vous pouvez :
- Choisir entre un planning quotidien ou hebdomadaire
- Personnaliser les activitÃ©s et ajouter des contraintes horaires
- Visualiser les plannings et leurs statistiques
- Exporter les plannings en CSV

### Exemple d'utilisation

1. SÃ©lectionnez "Planning quotidien" dans la barre latÃ©rale
2. Choisissez un jour (ex. : Lundi)
3. Activez ou personnalisez les activitÃ©s
4. Ajoutez des contraintes horaires (ex. : "Travail" de 9h Ã  12h)
5. Cliquez sur "GÃ©nÃ©rer planning quotidien" pour voir le planning optimisÃ© avec des visualisations interactives

![Optimized Schedule](..\ui\1.png)
![Optimized Schedule](..\ui\2.png)
![Optimized Schedule](..\ui\3.png)
![Optimized Schedule](..\ui\33.png)
![Optimized Schedule](..\ui\/44.png)
![Optimized Schedule](..\ui\222.png)
![Optimized Schedule](..ui\Sans-titre-2025-05-06-1603.png)

## ğŸ§  MÃ©thodologie

### Algorithme

Le projet utilise un **Deep Q-Network (DQN)**, un algorithme d'apprentissage par renforcement qui apprend Ã  maximiser une rÃ©compense cumulative en planifiant des activitÃ©s. Le DQN :

- Analyse les habitudes historiques des utilisateurs (heures prÃ©fÃ©rÃ©es, durÃ©es, frÃ©quences)
- Ã‰vite les conflits horaires et respecte les contraintes
- Optimise la cohÃ©rence et la satisfaction en regroupant les activitÃ©s similaires

### Environnement

L'environnement (`schedule_env.py`) est construit avec OpenAI Gym :

- **Espace d'actions** : Choix d'une activitÃ© et d'un crÃ©neau horaire
- **Espace d'observation** : Inclut l'agenda actuel, le jour de la semaine, et le temps restant
- **RÃ©compense** : BasÃ©e sur la proximitÃ© des activitÃ©s planifiÃ©es avec les prÃ©fÃ©rences historiques et la cohÃ©rence des plannings

### DonnÃ©es

Les donnÃ©es sont issues de l'American Time Use Survey (ATUS) ou de donnÃ©es synthÃ©tiques gÃ©nÃ©rÃ©es pour les tests. Les colonnes clÃ©s incluent :

- `ACTIVITY_NAME` : Nom de l'activitÃ©
- `TUACTDUR24` : DurÃ©e de l'activitÃ© (en minutes)
- `TUSTARTTIM` : Heure de dÃ©but
- `TUDIARYDAY` : Jour de la semaine

### Ã‰valuation

L'Ã©valuation repose sur :

- **ProductivitÃ©** : MesurÃ©e par la rÃ©compense totale du DQN
- **Satisfaction** : BasÃ©e sur l'alignement des plannings avec les prÃ©fÃ©rences historiques
- **Visualisations** : Graphiques interactifs pour analyser la rÃ©partition des activitÃ©s et les scores de productivitÃ©

## ğŸ“Š RÃ©sultats attendus

- **Plannings optimisÃ©s** : Horaires cohÃ©rents et adaptÃ©s aux prÃ©fÃ©rences de l'utilisateur
- **Visualisations claires** : Graphiques Plotly pour une comprÃ©hension facile des plannings
- **Statistiques utiles** : Identification des heures les plus productives et de la rÃ©partition des activitÃ©s

## âš ï¸ Limitations

- Les donnÃ©es synthÃ©tiques peuvent ne pas reflÃ©ter parfaitement les comportements rÃ©els
- Le modÃ¨le DQN nÃ©cessite un entraÃ®nement suffisant pour converger vers des plannings optimaux
- Les contraintes horaires complexes peuvent rÃ©duire la flexibilitÃ© du modÃ¨le

## ğŸ”® AmÃ©liorations futures

- IntÃ©gration de donnÃ©es utilisateur en temps rÃ©el via une API
- Prise en charge de contraintes multi-jours et de dÃ©pendances entre activitÃ©s
- Optimisation de l'algorithme avec des variantes avancÃ©es (Double DQN, Dueling DQN)
- AmÃ©lioration de l'interface avec des options de personnalisation avancÃ©es

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le dÃ©pÃ´t
2. CrÃ©ez une branche pour vos modifications (`git checkout -b feature/amÃ©lioration`)
3. Soumettez une pull request avec une description claire des changements

## ğŸ“„ Licence

Ce projet est sous licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
---

â­ N'hÃ©sitez pas Ã  donner une Ã©toile au projet si vous l'avez trouvÃ© utile !



 


